version: '3.8'
services:
  proxy:
    image: wz-nvidia-nixl:8.13
    container_name: proxy
    privileged: true
    shm_size: 64g
    runtime: nvidia
    working_dir: /workspace/examples/online_serving/disaggregated_serving_p2p_nccl_xpyd
    command: python3 disagg_proxy_p2p_nccl_xpyd.py
    volumes:
      - /data2:/workspace
    cap_add:
      - SYS_PTRACE
    security_opt:
      - seccomp=unconfined
    ports:
      - "30001:30001"
    networks:
      - wz-pd

  prefill:
    image: wz-nvidia-nixl:8.13
    container_name: prefill
    privileged: true
    shm_size: 64g
    runtime: nvidia
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - VLLM_USE_V1=1
    working_dir: /workspace/examples/online_serving/disaggregated_serving_p2p_nccl_xpyd
    command: >
      VLLM_LOGGING_LEVEL=DEBUG VLLM_USE_V1=1 CUDA_VISIBLE_DEVICES=2 vllm serve /workspace/models/Llama-3.1-8B-Instruct \
          --host 0.0.0.0 \
          --port 20001 \
          --tensor-parallel-size 1 \
          --seed 1024 \
          --served-model-name /workspace/models/Llama-3.1-8B-Instruct \
          --dtype float16 \
          --max-model-len 32768 \
          --max-num-batched-tokens 131072 \
          --max-num-seqs 256 \
          --trust-remote-code \
          --gpu-memory-utilization 0.9 \
          --kv-transfer-config \
          '{"kv_connector":"P2pNcclConnector","kv_role":"kv_producer","kv_buffer_size":"1e1","kv_port":"21001","kv_connector_extra_config":{"proxy_ip":"0.0.0.0","proxy_port":"30001","http_port":"20001","send_type":"PUT_ASYNC","nccl_num_channels":"8"}}' > prefill1.log 2>&1 &
    volumes:
      - /data2:/workspace
    cap_add:
      - SYS_PTRACE
    security_opt:
      - seccomp=unconfined
    depends_on:
      - proxy
    networks:
      - wz-pd

  decode:
    image: wz-nvidia-nixl:8.13
    container_name: decode
    privileged: true
    shm_size: 64g
    runtime: nvidia
    environment:
      - CUDA_VISIBLE_DEVICES=1
      - VLLM_USE_V1=1
    working_dir: /workspace/examples/online_serving/disaggregated_serving_p2p_nccl_xpyd
    command: >
      VLLM_LOGGING_LEVEL=DEBUG VLLM_USE_V1=1 CUDA_VISIBLE_DEVICES=3 vllm serve /workspace/models/Llama-3.1-8B-Instruct \
          --host 0.0.0.0 \
          --port 20003 \
          --tensor-parallel-size 1 \
          --seed 1024 \
          --served-model-name /workspace/models/Llama-3.1-8B-Instruct \
          --dtype float16 \
          --max-model-len 32768 \
          --max-num-batched-tokens 131072 \
          --max-num-seqs 256 \
          --trust-remote-code \
          --gpu-memory-utilization 0.7 \
          --kv-transfer-config \
          '{"kv_connector":"P2pNcclConnector","kv_role":"kv_consumer","kv_buffer_size":"2e10","kv_port":"23001","kv_connector_extra_config":{"proxy_ip":"0.0.0.0","proxy_port":"30001","http_port":"20003","send_type":"PUT_ASYNC","nccl_num_channels":"8"}}' > decode1.log 2>&1 &
    volumes:
      - /data2:/workspace
    cap_add:
      - SYS_PTRACE
    security_opt:
      - seccomp=unconfined
    depends_on:
      - proxy
    networks:
      - wz-pd

  benchmark:
    image: wz-nvidia-nixl:8.13
    container_name: benchmark
    privileged: true
    shm_size: 64g
    runtime: nvidia
    working_dir: /workspace/benchmarks
    command: >
      python3 benchmark_serving.py \
          --backend vllm \
          --model /workspace/models/Llama-3.1-8B-Instruct \
          --tokenizer /workspace/models/Llama-3.1-8B-Instruct \
          --dataset-name "random" \
          --host 127.0.0.1 \
          --port 10007 \
          --random-input-len 1024 \
          --random-output-len 200 \
          --ignore-eos \
          --burstiness 100 \
          --percentile-metrics "ttft,tpot,itl,e2el" \
          --metric-percentiles "90,95,99" \
          --seed 1024 \
          --trust-remote-code \
          --request-rate 7.5 \
          --num-prompts 2250
    volumes:
      - /data2:/workspace
    cap_add:
      - SYS_PTRACE
    security_opt:
      - seccomp=unconfined
    depends_on:
      - prefill
      - decode
    networks:
      - wz-pd

networks:
  wz-pd:
    driver: bridge